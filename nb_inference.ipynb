{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f133549e-49a7-44a0-b444-f374ea7df62b",
   "metadata": {},
   "source": [
    "# Inference base Phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd57c959-07d1-4c0f-b730-86f7bf454936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e909947bae84952a05411c86c8b2b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "modelpath=\"microsoft/phi-2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37acf578-0205-4efb-bfb7-25ac980804c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meaning of life is a mystery that has puzzled philosophers, scientists, and ordinary people for centuries.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"The meaning of life is\"\n",
    "\n",
    "input_tokens = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "output_tokens = model.generate(**input_tokens)\n",
    "output = tokenizer.decode(output_tokens[0])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11380acc-a271-407c-b3ed-eef5c36df6ca",
   "metadata": {},
   "source": [
    "# Inference fine-tuned Phi-2 (ChatML prompt format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17f078a-2928-4702-b719-587aadcc789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fd0976f2f8454f8f9a31c3c56d6c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "modelpath=\"g-ronimo/phi-2_riddles-evolved\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e14065-bb00-41c0-8745-4da3e92adccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50297 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "What is the meaning of life?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The meaning of life is a philosophical question that has been pondered by many people throughout history. There is no definitive answer, as different people may have different beliefs and perspectives on what gives life meaning. Some common answers include:\n",
      "\n",
      "1. Living a fulfilling and purposeful life: This perspective suggests that the meaning of life is to find happiness, satisfaction, and a sense of purpose in one's daily activities and relationships.\n",
      "2. Pursuing knowledge and understanding: This perspective suggests that the meaning of life is to seek knowledge, wisdom, and understanding of the world around us.\n",
      "3. Making a positive impact on the world: This perspective suggests that the meaning of life is to contribute to the greater good and make a positive difference in the lives of others.\n",
      "4. Experiencing love and connection: This perspective suggests that the meaning of life is to form deep and meaningful relationships with others and experience love and connection.\n",
      "5. Living in harmony with nature: This perspective suggests that\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the meaning of life?\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]\n",
    "        \n",
    "input_tokens = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "output_tokens = model.generate(input_tokens, max_new_tokens=200)\n",
    "output = tokenizer.decode(output_tokens[0])\n",
    "\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
